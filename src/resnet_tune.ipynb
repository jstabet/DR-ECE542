{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b22cc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-04-11 12:37:06,598] A new study created in memory with name: no-name-f6f9c83a-6ad8-4881-b470-8aef5825304d\n",
      "[I 2025-04-11 12:39:49,047] Trial 0 finished with value: 0.23690205011389523 and parameters: {'undersample': True, 'optimizer': 'SGD', 'lr': 5.4439884808594094e-05, 'dropout1': 0.5985329872832813, 'dropout2': 0.4411090099148564, 'hidden1': 1792, 'hidden2': 640, 'num_fc_layers': 1, 'weighted_loss': True, 'unfreeze_layer4': True}. Best is trial 0 with value: 0.23690205011389523.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from utils import DRDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import optuna\n",
    "\n",
    "# Constants\n",
    "DESC = 'resnet_tune'\n",
    "DATA_PATH = '../data/preproc_train_imgs.pth'\n",
    "LABEL_CSV = '../data/trainLabels.csv'\n",
    "RESULT_DIR = f'../results/{DESC}'\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 5\n",
    "NUM_EPOCHS_TUNE = 50\n",
    "\n",
    "# Load and split data\n",
    "labels = pd.read_csv(LABEL_CSV)\n",
    "labels_train, labels_test = train_test_split(labels, test_size=0.3, stratify=labels['level'], random_state=42)\n",
    "labels_val, labels_test = train_test_split(labels_test, test_size=2/3, stratify=labels_test['level'], random_state=42)\n",
    "\n",
    "def undersample_df(df):\n",
    "    rus = RandomUnderSampler(random_state=42)\n",
    "    X_res, y_res = rus.fit_resample(df[['image']], df['level'])\n",
    "    return pd.DataFrame({'image': X_res['image'], 'level': y_res})\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def objective(trial):\n",
    "    # --- Hyperparameters ---\n",
    "    use_undersampling = trial.suggest_categorical('undersample', [True, False])\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['Adam', 'SGD'])\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-3, log=True)\n",
    "    dropout1 = trial.suggest_float('dropout1', 0.3, 0.7)\n",
    "    dropout2 = trial.suggest_float('dropout2', 0.2, 0.5)\n",
    "    hidden1 = trial.suggest_int('hidden1', 512, 2048, step=256)\n",
    "    hidden2 = trial.suggest_int('hidden2', 128, 1024, step=128)\n",
    "    num_fc_layers = trial.suggest_int('num_fc_layers', 1, 3)\n",
    "    hidden3 = trial.suggest_int('hidden3', 64, 512, step=64) if num_fc_layers == 3 else None\n",
    "    weighted_loss = trial.suggest_categorical('weighted_loss', [True, False])\n",
    "    unfreeze_layer4 = trial.suggest_categorical('unfreeze_layer4', [True, False])\n",
    "\n",
    "    # Dataset\n",
    "    train_labels_bal = undersample_df(labels_train) if use_undersampling else labels_train\n",
    "\n",
    "    train_data = DRDataset(train_labels_bal, DATA_PATH, preproc=models.ResNet50_Weights.DEFAULT.transforms())\n",
    "    val_data = DRDataset(labels_val, DATA_PATH, preproc=models.ResNet50_Weights.DEFAULT.transforms())\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    train_N = len(train_loader.dataset)\n",
    "    val_N = len(val_loader.dataset)\n",
    "\n",
    "    # Model\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "    model.requires_grad_(False)\n",
    "    if unfreeze_layer4:\n",
    "        for param in model.layer4.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "    fc_layers = [\n",
    "        nn.Linear(model.fc.in_features, hidden1),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(p=dropout1)\n",
    "    ]\n",
    "    if num_fc_layers >= 2:\n",
    "        fc_layers.extend([\n",
    "            nn.Linear(hidden1, hidden2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=dropout2)\n",
    "        ])\n",
    "    if num_fc_layers == 3:\n",
    "        fc_layers.extend([\n",
    "            nn.Linear(hidden2, hidden3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.Linear(hidden3, NUM_CLASSES)\n",
    "        ])\n",
    "    else:\n",
    "        fc_layers.append(nn.Linear(hidden2 if num_fc_layers == 2 else hidden1, NUM_CLASSES))\n",
    "\n",
    "    model.fc = nn.Sequential(*fc_layers)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # Loss\n",
    "    if weighted_loss:\n",
    "        weights = compute_class_weight('balanced', classes=np.arange(NUM_CLASSES), y=train_labels_bal['level'])\n",
    "        class_weights = torch.tensor(weights, dtype=torch.float32).to(DEVICE)\n",
    "        loss_fn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    else:\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr) if optimizer_name == 'Adam' else \\\n",
    "                torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "    # Training loop with pruning\n",
    "    for epoch in range(NUM_EPOCHS_TUNE):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation step per epoch\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                outputs = model(inputs)\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        val_acc = correct / total\n",
    "\n",
    "        # Report to Optuna and check for pruning\n",
    "        trial.report(val_acc, epoch)\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return val_acc\n",
    "\n",
    "# Optuna study with pruning\n",
    "pruner = optuna.pruners.MedianPruner(n_warmup_steps=3)\n",
    "study = optuna.create_study(direction='maximize', pruner=pruner)\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "# Save best result\n",
    "print('Best trial:', study.best_trial.params)\n",
    "with open(os.path.join(RESULT_DIR, 'best_params.txt'), 'w') as f:\n",
    "    f.write(str(study.best_trial.params))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
